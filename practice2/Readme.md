# üìä Multiplicaci√≥n de Matrices con Procesos Paralelos en C y Go

**Universidad de Antioquia**  
*Curso: Sistemas Operativos*  
*Pr√°ctica #2 - Multiplicaci√≥n de matrices con procesos*

## üë• Integrantes

* [x] [Maritza Tabarez C√°rdenas](https://github.com/MaritzaTC)
* [x] [Juan David Vasquez Ospina](https://github.com/JuanVasquezO)

## üéØ Objetivos

<details>
<summary>Ver objetivos del proyecto</summary>
<br><br>

- Comprender la creaci√≥n de procesos usando `fork()`.
- Implementar c√≥mputo paralelo dividiendo la carga de trabajo entre m√∫ltiples procesos (en C) o gorutinas (en Go) usando APIs del sistema operativo.
- Aprender y aplicar mecanismos de comunicaci√≥n entre procesos (IPC), como pipes o memoria compartida (en C), y canales o estructuras para compartir memoria (en Go).
- Analizar y comparar el rendimiento entre las implementaciones secuenciales y paralelas de la multiplicaci√≥n de matrices.

</details>

---

## üìù Descripci√≥n del problema

<details>
<summary>Ver descripci√≥n completa</summary>
<br><br>

Desarrollar un programa que multiplique dos matrices grandes:

* Matriz A (N√óM)
* Matriz B (M√óP)
* Resultado: Matriz C (N√óP)

</details>

# üñ•Ô∏è Implementaci√≥n en C

## üîç Versiones implementadas

<details>
<summary>Ver versiones</summary>
<br><br>

* Versi√≥n secuencial (`sequential.c`)
* Versi√≥n paralela con procesos (`parallel.c`) usando memoria compartida
* Version secuencial y paralela (`sequientialAndParallel.c`)

</details>

## ‚öôÔ∏è Compilaci√≥n y ejecuci√≥n

<details>
<summary>Instrucciones de compilaci√≥n</summary>
<br><br>

Usar `gcc` para compilar:

```bash
gcc sequential.c -o sequential
gcc parallel.c -o parallel
gcc sequientialAndParallel.c -o parallel_matrix_multiply
```

</details>

<details>
<summary>Instrucciones de ejecuci√≥n</summary>
<br><br>

```bash
./sequential
./parallel
```

Al ejecutar, el programa pedir√° las dimensiones de las matrices (N, M, P) y leer√° los datos desde los archivos A.txt y B.txt. El resultado se escribir√° en C.txt.

</details>

## üìÅ Entrada y Salida

<details>
<summary>Ver detalles</summary>
<br><br>

* **Entrada**: Archivos A.txt, A\_small.txt, A\_big y B.txt, B\_small.txt, B\_big con los valores de las matrices.
* **Salida**: Archivo C.txt con la matriz resultado.

</details>

## üîÑ Mecanismo IPC en C

<details>
<summary>Ver justificaci√≥n t√©cnica</summary>
<br><br>

Para la implementaci√≥n paralela, se utiliz√≥ memoria compartida (Shared Memory) mediante las funciones `shmget()` y `shmat()` de la API de System V.

Esta elecci√≥n se basa en:

* **Velocidad**: La memoria compartida permite el acceso directo a la regi√≥n com√∫n de memoria, lo que evita copias innecesarias de datos.
* **Simplicidad en agregaci√≥n**: Los procesos hijos escriben directamente en la matriz C, eliminando la necesidad de combinar resultados tras el c√°lculo.
* **Escalabilidad**: Es m√°s eficiente que otros mecanismos como pipes para grandes vol√∫menes de datos.

</details>

## üìä An√°lisis de Rendimiento en C

<details>
<summary>Ver capturas de pantalla de resultados</summary>
<br><br>

![alt text](<Screenshot 2025-05-14 183333.png>)
![alt text](<Screenshot 2025-05-14 190748.png>)
![alt text](<Screenshot 2025-05-14 195626.png>)


</details>

<details>
<summary>Ver tabla de tiempos y speedup</summary>
<br><br>

| N   | M   | P   | N¬∫ Procesos | Tiempo Secuencial (s) | Tiempo Paralelo (s) | Speedup |
| --- | --- | --- | ----------- | --------------------- | ------------------- | ------- |
| 12  | 15  | 10  | 1           | 0.0001                | 0.0019              | 0.05    |
| 12  | 15  | 10  | 2           | 0.0001                | 0.0027              | 0.03    |
| 12  | 15  | 10  | 3           | 0.0001                | 0.0037              | 0.02    |
| 12  | 15  | 10  | 4           | 0.0001                | 0.0045              | 0.02    |
| 2   | 3   | 2   | 1           | 0.0001                | 0.0015              | 0.05    |
| 2   | 3   | 2   | 2           | 0.0001                | 0.0028              | 0.02    |
| 2   | 3   | 2   | 3           | 0.0001                | 0.0036              | 0.02    |
| 2   | 3   | 2   | 4           | 0.0001                | 0.0044              | 0.02    |
| 400 | 360 | 400 | 1           | 1.0425                | 0.0386              | 26.99   |
| 400 | 360 | 400 | 2           | 0.8743                | 0.0212              | 41.26   |
| 400 | 360 | 400 | 3           | 0.9131                | 0.0347              | 26.34   |
| 400 | 360 | 400 | 4           | 0.9994                | 0.0491              | 20.33   |

</details>

<details>
<summary>Ver gr√°fico de Speedup vs N√∫mero de Procesos</summary>
<br><br>

![alt text](Figure_1.png)


</details>

### üìà Interpretaci√≥n de resultados en C

<details>
<summary>Para matrices peque√±as (2x3 x 3x2 y 12x15 x 15x10)</summary>
<br><br>

* El speedup es muy bajo, incluso menor que 1 en algunos casos, lo que indica que la versi√≥n paralela no es eficiente para estos tama√±os peque√±os.
* De hecho, el tiempo paralelo es incluso mayor que el secuencial, reflejado en speedups menores a 1 (0.05, 0.02, etc.).
* Esto se debe a que la sobrecarga de crear y gestionar procesos, sincronizar y dividir el trabajo supera cualquier beneficio que se obtenga al paralelizar la multiplicaci√≥n de matrices tan peque√±as.
* Adem√°s, aumentar el n√∫mero de procesos no mejora significativamente el rendimiento; en algunos casos, lo empeora.

</details>

<details>
<summary>Para matrices grandes (400x360 x 360x400)</summary>
<br><br>

* El speedup es mucho mayor, llegando a valores superiores a 20 o 40 en algunos casos, lo que indica que la paralelizaci√≥n s√≠ da un gran beneficio.
* Esto es esperado porque con matrices grandes la carga de trabajo es mayor, por lo que dividir la tarea entre procesos reduce mucho el tiempo total.
* Sin embargo, el speedup no crece de forma perfectamente lineal con el n√∫mero de procesos: hay un m√°ximo (41.26 con 2 procesos) y luego baja.
* Esta ca√≠da puede ser causada por la sobrecarga de comunicaci√≥n y sincronizaci√≥n entre procesos cuando se usan m√°s de dos procesos, o limitaciones de hardware (como n√∫mero de n√∫cleos f√≠sicos disponibles).
* A√∫n as√≠, la paralelizaci√≥n es claramente beneficiosa para cargas de trabajo grandes.

</details>

---

# üöÄ Implementaci√≥n en Go

## üìã Estructura del Programa

<details>
<summary>Ver estructura completa</summary>
<br><br>

#### Funciones para manejo de archivos:

* `readMatrixFromFile`: Lee los datos de la matriz desde un archivo de texto.
* `writeMatrixToFile`: Escribe la matriz resultante en un archivo de texto.

#### Multiplicaci√≥n de matrices:

* `workerMultiply`: Funci√≥n que realiza la multiplicaci√≥n parcial de matrices en una goroutine y env√≠a los resultados a trav√©s de un pipe.
* `multiplyMatricesParallelWithPipes`: Funci√≥n que crea las goroutines (workers), los pipes, distribuye el trabajo entre los workers y recoge los resultados de los pipes para construir la matriz final.
* `multiplyMatricesSequential`: Funci√≥n que realiza la multiplicaci√≥n de matrices de forma secuencial.

#### Funci√≥n main:

* Procesa los argumentos de la l√≠nea de comandos: nombres de los archivos de entrada para las matrices A y B, y el n√∫mero de workers (goroutines).
* Lee las matrices A y B desde los archivos.
* Realiza la multiplicaci√≥n de matrices de forma secuencial y paralela.
* Imprime los tiempos de ejecuci√≥n de ambas versiones y el speedup obtenido con la versi√≥n paralela.
* Escribe la matriz resultado en un archivo.

</details>


## ‚öôÔ∏è ejecuci√≥n

<details>
<summary>Instrucciones de ejecuci√≥n</summary>
<br><br>


```bash
go run matrix_mul.go A.txt B.txt 2
```

A.txt y B.txt son los nombres de las matrices por multiplicar, y el numero siguiente a este es el numero de procesos por el cual hacer la comparaci√≥n

</details>

## üìä An√°lisis de Rendimiento en Go

<details>
<summary>Ver tabla de tiempos</summary>
<br><br>

| N   | M   | P   | N¬∫ Procesos | Tiempo total (s) |
| --- | --- | --- | ----------- | ---------------- |
| 400 | 360 | 400 | 1           | 0.12201          |
| 400 | 360 | 400 | 2           | 0.218811         |
| 400 | 360 | 400 | 3           | 0.163926         |
| 400 | 360 | 400 | 4           | 0.143176         |
| 400 | 360 | 400 | 5           | 0.146358         |
| 400 | 360 | 400 | 6           | 0.131248         |
| 400 | 360 | 400 | 7           | 0.118516         |
| 400 | 360 | 400 | 8           | 0.124494         |
| 400 | 360 | 400 | 9           | 0.118718         |

</details>

<details>
<summary>Ver gr√°fico de Tiempo vs N√∫mero de Procesos</summary>
<br><br>

![Tiempo vs Procesos](https://github.com/user-attachments/assets/4d54ea9b-580d-43d4-9d1d-c49a4d7d5ce0)

</details>


## üîÑ Mecanismo IPC en Go

<details>
<summary>Ver detalles t√©cnicos</summary>
<br><br>

La implementaci√≥n paralela en Go utiliza pipes para la comunicaci√≥n entre las goroutines (workers). Cada worker calcula una porci√≥n de la matriz resultado y env√≠a los resultados (√≠ndices de la celda y valor calculado) a trav√©s de un pipe. La funci√≥n principal lee los resultados de los pipes y construye la matriz resultado final.

#### Paralelismo con Goroutines

Go utiliza goroutines para lograr la ejecuci√≥n paralela. La carga de trabajo se divide entre las goroutines, permitiendo que m√∫ltiples porciones de la matriz se calculen simult√°neamente.

</details>

---



# üîÑ Comparaci√≥n entre implementaciones

<details>
<summary>C vs Go</summary>
<br><br>

Aunque ambas implementaciones buscan paralelizar la multiplicaci√≥n de matrices, utilizan diferentes enfoques y mecanismos de IPC:

#### C:

* Utiliza procesos separados y memoria compartida para la comunicaci√≥n.
* Los procesos hijos escriben los resultados directamente en una regi√≥n de memoria compartida.

#### Go:

* Utiliza goroutines (que son m√°s ligeras que los procesos) y pipes para la comunicaci√≥n.
* Los workers env√≠an los resultados a trav√©s de pipes, y la goroutine principal los recoge.

Ambos enfoques tienen como objetivo mejorar el rendimiento al dividir la carga de trabajo, pero difieren en la forma en que se gestionan los procesos/goroutines y c√≥mo se comunican.

</details>

# üìö Referencias

<details>
<summary>Ver referencias</summary>
<br><br>

* OSTEP: Processes API Chapter.
* Linux man pages: `fork()`, `shmget()`, `pipe()`

</details>
